# ğŸ§  Alzheimer's Disease Prediction from MRI (OASIS Dataset)

Early prediction of **Alzheimerâ€™s Disease (AD)** using **MRI-based features** and a diverse set of **machine learning** and **deep learning** models.  
This repository includes endâ€‘toâ€‘end data analysis, model development, **rigorous evaluation** (ROCâ€‘AUC / Precision / Recall), and **interpretability** via Gradâ€‘CAM.

---

## ğŸ“– Overview
This project explores multiple approaches to predict Alzheimerâ€™s diagnosis from patient-level information with an emphasis on **clinical metrics** and **reproducibility**. We compare classical ML (Logit, LDA, CART, Random Forest, Bagging, Boosting, SVM), shallow/deep neural networks, and visualize CNN attention with **Gradâ€‘CAM**.  
The goal is to build reliable models that support early detection and can generalize without data leakage.

**Highlights**
- 74,283 samples, 25 features (4 numeric + 20 categorical)  
- Strict train/validation/test protocol (no leakage; scalers/encoders fit on train only)  
- Model selection with crossâ€‘validation; evaluation using ROCâ€‘AUC, Precision, Recall  
- Clinical orientation: prioritize **Recall** when minimizing False Negatives matters  
- Model interpretability with **Gradâ€‘CAM** for CNN variants

---

## ğŸ—‚ï¸ Dataset
- **Source**: Alzheimerâ€™s Prediction dataset (public/open source).  
- **Target**: Binary label â€” Alzheimerâ€™s diagnosis (Yes/No).  
- **Numeric features**: `Age`, `BMI`, `Education Level (years)`, `Cognitive Test Score`.  
- **Categorical features** (examples): `Gender`, `Genetic Risk Factor`, `Family History`, `Smoking`, `Physical Activity`, `Sleep Quality`, `Diabetes`, `Hypertension`, `Income Level`, etc.  
- **Missing values**: none observed in the analyzed snapshot.  
- **Standardization**: zâ€‘score scaling for numeric features.  
- **Encoding**: categorical variables cast to factor / oneâ€‘hot encoded in ML pipelines.

> âš ï¸ **Important**: If you work with MRI images, ensure patientâ€‘level splits (subjectâ€‘wise) to avoid leakage across train/test when multiple scans per subject exist.

---

## ğŸ§ª Experimental Setup
- **Split**: 70% train / 30% test (stratified), fixed seeds, crossâ€‘validated model selection.  
- **Thresholding**: thresholds swept to report both **Recall** and **Precision**; pick operating point by task (e.g., Youdenâ€‘J or FÎ² for recall priority).  
- **Pipelines**: All preprocessing happens **inside** `sklearn` pipelines to prevent leakage.  
- **Calibration**: optional probability calibration (e.g., isotonic) for clinically meaningful scores.

---

## ğŸ§  Models
- **Statistical / Classical ML**: Logistic Regression (Logit), Additive Logit + L1 (Lasso), **LDA**, **CART**, **Bagging**, **Random Forest**, **Boosting** (GLM Boosting, XGBoost), **SVM** (Linear & RBF).  
- **Neural Networks**: MLP / CNN for MRIâ€‘based learning.  
- **Explainability**: **Gradâ€‘CAM** to localize salient regions for CNN predictions.

---

## ğŸ“ˆ Results (Test Set)
The following results summarize the comparative performance across models:

| Model | Precision | Recall | ROCâ€‘AUC |
|---|---:|---:|---:|
| Logistic Regression | 0.6344 | 0.7170 | 0.7146 |
| Additive Logit + Lasso | 0.6290 | 0.7650 | 0.7989 |
| LDA | 0.4122 | 0.9517 | 0.5031 |
| CART | 0.6485 | 0.7316 | 0.7514 |
| Random Forest | 0.6628 | 0.6891 | 0.7820 |
| Bagging | 0.6589 | 0.6719 | 0.7318 |
| **XGBoost** | **0.7657** | 0.6291 | 0.7982 |
| **GLM Boosting (Best AUC)** | 0.7870 | 0.6264 | **0.8039** |
| SVM (Linear) | 0.6386 | 0.7239 | 0.7894 |
| SVM (RBF) | 0.6386 | 0.7238 | 0.7894 |

**Takeaways**
- **Boosting** methods (GLM, XGBoost) reach the **highest ROCâ€‘AUC (~0.80)**.  
- **Additive Logit + L1** offers a strong balance of **Recall** and interpretability.  
- In clinical settings, **higher Recall** can be preferred to minimize False Negatives.

> Note: Exact numbers may vary with seeds/splits. Please reâ€‘run with your environment and document your split/seed for full reproducibility.

---

## ğŸ§© Repository Structure (suggested)
```
Alzheimer-MRI-Prediction/
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_eda.ipynb
â”‚  â”œâ”€ 02_ml_models.ipynb          # Logit/LDA/CART/RF/Boosting/SVM
â”‚  â”œâ”€ 03_cnn_training.ipynb
â”‚  â”œâ”€ 04_gradcam.ipynb
â”œâ”€ src/
â”‚  â”œâ”€ data.py          # loaders, patient-wise split
â”‚  â”œâ”€ preprocess.py    # scaling/encoding inside sklearn pipelines
â”‚  â”œâ”€ models.py        # model builders
â”‚  â”œâ”€ train.py         # training loops & CV
â”‚  â”œâ”€ eval.py          # metrics, threshold sweep, calibration
â”‚  â”œâ”€ viz.py           # plots, Grad-CAM helpers
â”œâ”€ reports/figures/    # ROC/PR curves, confusion matrices, CAMs
â”œâ”€ models/             # saved weights (gitignored)
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âš™ï¸ Setup & Usage
1) **Clone**
```bash
git clone https://github.com/ziaee-mohammad/Alzheimer-MRI-Prediction.git
cd Alzheimer-MRI-Prediction
```

2) **Environment**
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

3) **Run notebooks / scripts**
- Open Jupyter and run notebooks in order (`notebooks/`).  
- Or use the scripts in `src/` to train/evaluate:
```bash
python -m src.train --model xgboost
python -m src.eval  --checkpoint path/to/model --threshold auto
```

4) **Gradâ€‘CAM**
```bash
python -m src.viz --checkpoint path/to/cnn --input path/to/mri.png --out reports/figures/cam.png
```

---

## ğŸ“¦ Requirements (example)
```
numpy
pandas
scikit-learn
matplotlib
seaborn
xgboost
torch            # or tensorflow (choose one DL backend)
torchvision
opencv-python
shap             # optional (explainability)
```

> Tip: Pin exact versions for full reproducibility.

---

## âœ… Reproducibility Checklist
- Set `random_state` everywhere (NumPy, sklearn, DL backend).  
- Perform **patientâ€‘level** splits; never mix a subjectâ€™s scans across train/test.  
- Fit scalers/encoders **only** on train; apply to val/test.  
- Report **ROCâ€‘AUC** and **PRâ€‘AUC**; include confusion matrices at multiple thresholds.  
- Consider **probability calibration** (`CalibratedClassifierCV`) for clinically meaningful scores.

---

## ğŸ§‘â€âš•ï¸ Ethical Considerations
- This repository is for **research and educational** purposes; not a medical device.  
- Models should not be used for clinical decisionâ€‘making without proper validation and oversight.

---

## ğŸ™Œ Acknowledgments
- Open data contributors and the research community for public datasets and benchmarks.  
- Methodological inspiration from public articles and tutorials. Please see citation notes in the repository if you adapt parts of this work.

---

## ğŸ‘¤ Author
**Mohammad Ziaee** â€“ Computer Engineer | AI & Data Science  
GitHub: https://github.com/ziaee-mohammad

